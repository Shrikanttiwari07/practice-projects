{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "name": ""
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "Project Description\nThe dataset is related to red and white variants of the Portuguese \"Vinho Verde\" wine. Due to privacy and logistic issues, only physicochemical (inputs) and sensory (the output) variables are available (e.g. there is no data about grape types, wine brand, wine selling price, etc.).\n\nThis dataset can be viewed as classification task. The classes are ordered and not balanced (e.g. there are many more normal wines than excellent or poor ones). Also, we are not sure if all input variables are relevant. So it could be interesting to test feature selection methods.\nAttribute Information\nInput variables (based on physicochemical tests):\n1 - fixed acidity\n2 - volatile acidity\n3 - citric acid\n4 - residual sugar\n5 - chlorides\n6 - free sulfur dioxide\n7 - total sulfur dioxide\n8 - density\n9 - pH\n10 - sulphates\n11 - alcohol\nOutput variable (based on sensory data):\n12 - quality (score between 0 and 10)\nWhat might be an interesting thing to do, is to set an arbitrary cutoff for your dependent variable (wine quality) at e.g. 7 or higher getting classified as 'good/1' and the remainder as 'not good/0'.\nThis allows you to practice with hyper parameter tuning on e.g. decision tree algorithms looking at the ROC curve and the AUC value.\nYou need to build a classification model. \nInspiration\nUse machine learning to determine which physiochemical properties make a wine 'good'!\n\nDataset Link-\nhttps://github.com/FlipRoboTechnologies/ML-Datasets/blob/main/Red%20Wine/winequality-red.csv\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import roc_curve, auc, accuracy_score, confusion_matrix\n\n# Load the dataset\nurl = 'https://github.com/FlipRoboTechnologies/ML-Datasets/blob/main/Red%20Wine/winequality-red.csv'\nwine_data = pd.read_csv(url, sep=';')\n\n# Define feature matrix X and target variable y\nX = wine_data.drop('quality', axis=1)\ny = (wine_data['quality'] >= 7).astype(int)  # Convert to binary: 1 for good (>= 7), 0 for not good (< 7)\n\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize RandomForestClassifier (you can use other classifiers as well)\nrf = RandomForestClassifier(random_state=42)\n\n# Perform GridSearchCV for hyperparameter tuning\nparam_grid = {\n    'n_estimators': [50, 100, 200],\n    'max_depth': [None, 10, 20],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4]\n}\n\ngrid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='roc_auc')\ngrid_search.fit(X_train, y_train)\n\n# Select the best model from GridSearchCV\nbest_rf = grid_search.best_estimator_\n\n# Predict on the test set\ny_pred = best_rf.predict(X_test)\ny_pred_proba = best_rf.predict_proba(X_test)[:, 1]\n\n# Calculate evaluation metrics\naccuracy = accuracy_score(y_test, y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\nfpr, tpr, _ = roc_curve(y_test, y_pred_proba)\nroc_auc = auc(fpr, tpr)\n\nprint(f'Accuracy: {accuracy:.4f}')\nprint(f'Confusion Matrix:\\n{conf_matrix}')\nprint(f'ROC-AUC: {roc_auc:.4f}')\n\n# Plot ROC curve\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, color='blue', lw=2, label=f'AUC = {roc_auc:.2f}')\nplt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--', label='Random')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc='lower right')\nplt.show()\n\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Project Description\nHealth insurance is a type of insurance that covers medical expenses that arise due to an illness. These expenses could be related to hospitalisation costs, cost of medicines or doctor consultation fees. The main purpose of medical insurance is to receive the best medical care without any strain on your finances. Health insurance plans offer protection against high medical costs. It covers hospitalization expenses, day care procedures, domiciliary expenses, and ambulance charges, besides many others. Based on certain input features such as age , bmi,,no of dependents ,smoker ,region  medical insurance is calculated .\nColumns                                            \n•\tage: age of primary beneficiary\n•\tsex: insurance contractor gender, female, male\n•\tbmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height, objective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9.\n•\tchildren: Number of children covered by health insurance / Number of dependents\n•\tsmoker: Smoking\n•\tregion: the beneficiary's residential area in the US, northeast, southeast, southwest, northwest.\n•\tcharges: Individual medical costs billed by health insurance\n\nPredict : Can you accurately predict insurance costs?\n\nDataset Link-\nhttps://github.com/FlipRoboTechnologies/ML-Datasets/blob/main/Medical%20Cost%20Insurance/medical_cost_insurance.csv\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nimport numpy as np\n\n# Load the dataset\nurl = 'https://github.com/FlipRoboTechnologies/ML-Datasets/blob/main/Medical%20Cost%20Insurance/medical_cost_insurance.csv'\ninsurance_data = pd.read_csv(url)\n\n# Separate features (X) and target variable (y)\nX = insurance_data.drop('charges', axis=1)\ny = insurance_data['charges']\n\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Preprocessing pipeline for numeric and categorical features\nnumeric_features = ['age', 'bmi', 'children']\ncategorical_features = ['sex', 'smoker', 'region']\n\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())\n])\n\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_features),\n        ('cat', categorical_transformer, categorical_features)\n    ])\n\n# Append classifier to preprocessing pipeline\nlr_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('regressor', LinearRegression())])\n\n# Fit the model\nlr_pipeline.fit(X_train, y_train)\n\n# Predict on the test set\ny_pred = lr_pipeline.predict(X_test)\n\n# Model evaluation\nmse = mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(mse)\nr2 = r2_score(y_test, y_pred)\n\nprint(f'Mean Squared Error: {mse:.2f}')\nprint(f'Root Mean Squared Error: {rmse:.2f}')\nprint(f'R-squared: {r2:.2f}')\n\n# Example prediction for a new data point\nnew_data_point = pd.DataFrame([{'age': 40, 'sex': 'male', 'bmi': 30, 'children': 2, 'smoker': 'yes', 'region': 'southwest'}])\npredicted_cost = lr_pipeline.predict(new_data_point)\nprint(f'Predicted insurance cost for the new data point: ${predicted_cost[0]:.2f}')\n\n\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}